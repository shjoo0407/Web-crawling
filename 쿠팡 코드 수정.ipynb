{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교수님 코드 수정 버전\n",
    "#### '식품' 카테고리 클릭후의 현재 url은 다음과 같다.\n",
    "#### 현재 url = 'https://www.coupang.com/np/categories/194276'\n",
    "#### 뒤에 가고싶은 페이지 넘버를 붙어 '?page=n' 형식으로 만들어서\n",
    "#### GET 방식으로 url을 만들어 우리가 보는 브라우저 페이지처럼 만들어서\n",
    "#### driver.get(next_page)로 환경을 설정한다.\n",
    "-------------------------------------------------\n",
    "- next_page = driver.current_url + '?page=1'\n",
    "- driver.delete_all_cookies()\n",
    "- time.sleep(1)\n",
    "- driver.get(next_page)\n",
    "- time.sleep(3)\n",
    "\n",
    "-------------------------------------------------\n",
    "\n",
    "#### 그 후에는 아래 리스트가 생겨서 XPATH로 접근 할 수 있다.\n",
    "#### click() 전에 쿠키를 항상 지워야 한다.\n",
    "\n",
    "-------------------------------------------------\n",
    "- driver.delete_all_cookies()\n",
    "- time.sleep(1)\n",
    "- driver.find_element(By.XPATH, '...')\n",
    "\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1. 필요한 모듈과 라이브러리를 로딩합니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import urllib.request\n",
    "import urllib\n",
    "import time\n",
    "import pandas as pd    \n",
    "import os\n",
    "import math\n",
    "\n",
    "#Step 2. 사용자에게 검색어 키워드를 입력 받습니다.\n",
    "print(\"=\" *80)\n",
    "print(\" 쿠팡 사이트의 식품 카테고리 Best Seller 상품 정보 추출하기 \")\n",
    "print(\"=\" *80)\n",
    "\n",
    "cnt = int(input('1.크롤링 할 건수는 몇건입니까?: '))\n",
    "page_cnt = math.ceil(cnt/60)\n",
    "\n",
    "f_dir = input(\"2.파일을 저장할 폴더명만 쓰세요(기본경로:c:\\\\py_temp\\\\):\")\n",
    "if f_dir == '' :\n",
    "    f_dir = \"c:\\\\py_temp\\\\\"\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "if cnt > 30 :\n",
    "      print(\"    요청 건수가 많아서 시간이 제법 소요되오니 잠시만 기다려 주세요~~\")\n",
    "else :\n",
    "      print(\"    요청하신 데이터를 수집하고 있으니 잠시만 기다려 주세요~~\")\n",
    "\n",
    "#Step 3.저장될 파일 경로와 이름을 지정합니다\n",
    "sec_name = '식품'\n",
    "query_txt='쿠팡'\n",
    "\n",
    "n = time.localtime()\n",
    "s1 = '%04d-%02d-%02d-%02d-%02d-%02d' % (n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "\n",
    "os.makedirs(f_dir+s1+'-'+query_txt+'-'+sec_name)\n",
    "os.chdir(f_dir+s1+'-'+query_txt+'-'+sec_name)\n",
    "\n",
    "ff_dir=f_dir+s1+'-'+query_txt+'-'+sec_name\n",
    "ff_name=f_dir+s1+'-'+query_txt+'-'+sec_name+'\\\\'+s1+'-'+query_txt+'-'+sec_name+'.txt'\n",
    "fc_name=f_dir+s1+'-'+query_txt+'-'+sec_name+'\\\\'+s1+'-'+query_txt+'-'+sec_name+'.csv'\n",
    "fx_name=f_dir+s1+'-'+query_txt+'-'+sec_name+'\\\\'+s1+'-'+query_txt+'-'+sec_name+'.xls'\n",
    "\n",
    "# 제품 이미지 저장용 폴더 생성\n",
    "img_dir = ff_dir+\"\\\\images\"\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir)\n",
    "    \n",
    "s_time = time.time( )\n",
    "\n",
    "#Step 4. 웹사이트 접속 후 해당 메뉴로 이동합니다.\n",
    "s = Service(\"C:/Users/82107/2-WebCrawling/py_tmp/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "query_url='https://www.coupang.com/'\n",
    "driver.get(query_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# # Access Denied 메시지가 나오면 아래코드로 쿠키를 삭제한다\n",
    "driver.delete_all_cookies()\n",
    "time.sleep(2)\n",
    "\n",
    "# 분야별 더보기 버튼을 눌러 페이지를 엽니다\n",
    "driver.find_element(By.XPATH , '//*[@id=\"header\"]/div').click( )\n",
    "# 왠지는 모르겠는데 클릭 후에 코드가 뻗는 버그가 있어 try-except 문으로 예외처리해서\n",
    "# 다음 코드로 강제진행하도록 했다.\n",
    "try:\n",
    "    driver.find_element(By.XPATH , '//*[@id=\"gnbAnalytics\"]/ul[1]/li[4]/a').click( )\n",
    "except:\n",
    "    print('done')\n",
    "##########################################################################    \n",
    "# '식품' 카테고리 클릭후의 현재 url은 다음과 같다.\n",
    "# 현재 url = 'https://www.coupang.com/np/categories/194276'\n",
    "# 뒤에 가고싶은 페이지 넘버를 붙어 '?page=n' 형식으로 만들어서\n",
    "# GET 방식으로 url을 만들어 우리가 보는 브라우저 페이지처럼 만들어서\n",
    "# driver.get(next_page)로 환경을 설정한다.\n",
    "next_page = driver.current_url + '?page=1'\n",
    "driver.delete_all_cookies()\n",
    "time.sleep(1)\n",
    "driver.get(next_page)\n",
    "time.sleep(3)\n",
    "#########################################################################\n",
    "#Step 5. 내용을 수집합니다\n",
    "print(\"\\n\")\n",
    "print(\"===== 곧 수집된 결과를 출력합니다 ^^ ===== \")\n",
    "print(\"\\n\")\n",
    "\n",
    "ranking2=[]        #제품의 판매순위 저장\n",
    "title2=[]          #제품 정보 저장\n",
    "p_price2=[]        #현재 판매가 저장\n",
    "discount2 = []     #할인율 저장\n",
    "sat_count2=[]      #상품평 수 저장\n",
    "\n",
    "img_src2=[]   # 이미지 URL 저장변수\n",
    "file_no = 0   # 이미지 파일 저장할 때 번호\n",
    "count = 1     # 총 게시물 건수 카운트 변수\n",
    "\n",
    "def scroll_down(driver):      \n",
    "    driver.execute_script(\"window.scrollBy(0,1100);\")\n",
    "    time.sleep(4)\n",
    "\n",
    "for x in range(1,page_cnt + 1) :\n",
    "    \n",
    "    for cc in range(1,7) :\n",
    "        scroll_down(driver)\n",
    "        \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    item_result = soup.find('ul','baby-product-list').find_all('li')\n",
    "\n",
    "    for li in item_result :\n",
    "        if cnt < count :\n",
    "            break\n",
    "\n",
    "        # 제품 이미지 다운로드 하기\n",
    "        try :\n",
    "            photo = li.find('dt','image').find('img')['src']\n",
    "        except AttributeError :\n",
    "            continue\n",
    "\n",
    "        file_no += 1\n",
    "        full_photo = 'https:' + photo\n",
    "        urllib.request.urlretrieve(full_photo,str(file_no)+'.jpg')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        #제품 내용 추출하기\n",
    "        f = open(ff_name, 'a',encoding='UTF-8')\n",
    "        f.write(\"-----------------------------------------------------\"+\"\\n\")\n",
    "        print(\"-\" *70)\n",
    "\n",
    "        ranking = count\n",
    "        print(\"1.판매순위:\",ranking)\n",
    "        f.write('1.판매순위:'+ str(ranking) + \"\\n\")\n",
    "\n",
    "        try :\n",
    "            t = li.find('div','name').get_text().replace(\"\\n\",\"\")\n",
    "        except :\n",
    "            title = '제품소개가 없습니다'\n",
    "            print(title.replace(\"\\n\",\"\"))\n",
    "            f.write('2.제품소개:'+ title + \"\\n\")\n",
    "        else :\n",
    "            title = t.replace(\"\\n\",\"\").strip()\n",
    "            print(\"2.제품소개:\", title.replace(\"\\n\",\"\").strip())                  \n",
    "            f.write('2.제품소개:'+ title + \"\\n\")\n",
    "\n",
    "        try :\n",
    "            p_price = li.find('strong','price-value').get_text().replace(\"\\n\",\"\")\n",
    "        except :\n",
    "            p_price = '0'\n",
    "            print(\"3.판매가격:\", p_price.replace(\"\\n\",\"\"))\n",
    "            f.write('3.판매가격:'+ p_price + \"\\n\")\n",
    "        else :\n",
    "            print(\"3.판매가격:\", p_price.replace(\"\\n\",\"\"))\n",
    "            f.write('3.판매가격:'+ p_price + \"\\n\")\n",
    "\n",
    "        try :\n",
    "            discount = li.find('span','discount-percentage').get_text().replace(\"\\n\",\"\")\n",
    "        except  :\n",
    "            discount = '0'\n",
    "            print(\"4:할인률:\", discount)\n",
    "            f.write('4.할인율:'+ discount + \"\\n\")\n",
    "        else :\n",
    "            print(\"4:할인률:\", discount)\n",
    "            f.write('4.할인율:'+ discount + \"\\n\")\n",
    "\n",
    "        try :\n",
    "            sat_count_1 = li.find('span','rating-total-count').get_text()\n",
    "            sat_count_2 = sat_count_1.replace(\"(\",\"\").replace(\")\",\"\")\n",
    "        except  :\n",
    "            sat_count_2='0'\n",
    "            print('5.상품평 수: ',sat_count_2)\n",
    "            f.write('5.상품평 수:'+ sat_count_2 + \"\\n\")\n",
    "        else :\n",
    "            print('5.상품평 수:',sat_count_2)\n",
    "            f.write('5.상품평 수:'+ sat_count_2 + \"\\n\")\n",
    "\n",
    "        print(\"-\" *70)\n",
    "\n",
    "        f.close( )             \n",
    "        time.sleep(0.5)\n",
    "\n",
    "        ranking2.append(ranking)\n",
    "        title2.append(title.replace(\"\\n\",\"\"))\n",
    "\n",
    "        p_price2.append(p_price.replace(\"\\n\",\"\"))\n",
    "        discount2.append(discount)\n",
    "\n",
    "        try :   \n",
    "            sat_count2.append(sat_count_2)\n",
    "        except IndexError :\n",
    "            sat_count2.append(0)\n",
    "\n",
    "        count += 1\n",
    "    x += 1       \n",
    "    try :\n",
    "        #######################################################\n",
    "        #click() 전에 쿠키를 지운다.\n",
    "        driver.delete_all_cookies()\n",
    "        time.sleep(1)\n",
    "        #######################################################\n",
    "        driver.find_element(By.LINK_TEXT, '%s' %x).click() # 다음 페이지번호 클릭\n",
    "    except :\n",
    "        break\n",
    "          \n",
    "#step 6. csv , xls 형태로 저장하기              \n",
    "co_best_seller = pd.DataFrame()\n",
    "co_best_seller['판매순위']=ranking2\n",
    "co_best_seller['제품소개']=pd.Series(title2)\n",
    "co_best_seller['제품판매가']=pd.Series(p_price2)\n",
    "co_best_seller['할인율']=pd.Series(discount2)\n",
    "co_best_seller['상품평수']=pd.Series(sat_count2)\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "co_best_seller.to_csv(fc_name,encoding=\"utf-8-sig\",index=False)\n",
    "\n",
    "# 엑셀 형태로 저장하기\n",
    "co_best_seller.to_excel(fx_name ,index=False , engine='openpyxl')\n",
    "\n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "count -= 1\n",
    "print(\"\\n\")\n",
    "print(\"=\" *80)\n",
    "print(\"1.요청된 총 %s 건의 리뷰 중에서 실제 크롤링 된 리뷰수는 %s 건입니다\" %(cnt,count))\n",
    "print(\"2.총 소요시간은 %s 초 입니다 \" %round(t_time,1))\n",
    "print(\"3.파일 저장 완료: txt 파일명 : %s \" %ff_name)\n",
    "print(\"4.파일 저장 완료: csv 파일명 : %s \" %fc_name)\n",
    "print(\"5.파일 저장 완료: xls 파일명 : %s \" %fx_name)\n",
    "print(\"=\" *80)\n",
    "\n",
    "#Step 7. xls 파일에 제품 이미지 삽입하기\n",
    "import win32com.client as win32   #pywin32 , pypiwin32 설치후 동작\n",
    "import win32api                   #파이썬 프롬프트를 관리자 권한으로 실행해야 에러없음\n",
    "                     \n",
    "excel = win32.gencache.EnsureDispatch('Excel.Application')\n",
    "wb = excel.Workbooks.Open(fx_name)\n",
    "sheet = wb.ActiveSheet\n",
    "sheet.Columns(2).ColumnWidth = 30   \n",
    "row_cnt = cnt+1\n",
    "sheet.Rows(\"2:%s\" %row_cnt).RowHeight = 120   \n",
    "\n",
    "ws = wb.Sheets(\"Sheet1\")\n",
    "col_name2=[]\n",
    "file_name2=[]\n",
    "\n",
    "for a in range(2,cnt+2) :\n",
    "    col_name='B'+str(a)\n",
    "    col_name2.append(col_name)\n",
    "\n",
    "for b in range(1,cnt+1) :\n",
    "    file_name=img_dir+'\\\\'+str(b)+'.jpg'\n",
    "    file_name2.append(file_name)\n",
    "      \n",
    "for i in range(0,cnt) :\n",
    "    rng = ws.Range(col_name2[i])\n",
    "    image = ws.Shapes.AddPicture(file_name2[i], False, True, rng.Left, rng.Top, 130, 100)\n",
    "    excel.Visible=True\n",
    "    excel.ActiveWorkbook.Save()\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
